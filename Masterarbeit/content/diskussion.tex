

Nachdem im letzten Kapitel die Ergebnisse präsentiert wurden, soll in diesem Kapitel versucht werden mit Hilfe der Ergebnisse die Forschungsfrage zu beantworten.

\section{Kodierung}

\subsection{Items}

Da sowohl die Qualitätsstandards als auch die Niveaus auf den Items basieren, ist eine gute Kodierung derselbigen elementar für diese. Durch die Zweitkodierung der Items sollte sichergestellt werden, dass die Kodierung der Items verlässlich und wiederholbar ist. In Tabelle \ref{tab:CohenKappa} sind die Ergebnisse für die Interrater-Reliabilität aufgeführt. Bis auf wenige Ausnahmen befinden sich alle Werte oberhalb von $\kappa > 0.75$ was nach \citet[S.111]{Greve1997} sehr gut bis ausgezeichnet ist. \citet{Landis1977} bezeichnet jedoch auch die niedrigen $\kappa$-Werte bei denen $\kappa > 0.61$ ist als "`substantial strength of agreement'. 

Ein Problem bei der Kodierung der Items und der Überprüfung, war jedoch, dass viele Schülerinnen und Schüler bestimmte Items nicht erreichten. Daher konnte Cohen's $\kappa$ nicht für alle Items berechnet werden. Da die prozedurale Übereinstimmung dort jedoch sehr hoch war, kann auch bei diesen Items von einer korrekten Kodierung ausgegangen werden. Dieses Problem kann auch eine Erklärung für die sehr gute Übereinstimmung bei bestimmten Items sein. So war es meistens sehr klar, wenn ein Schüler oder eine Schülerin ein Item nicht erreicht hatten. Daher war die Kodierung meistens sehr eindeutig.

Aufgrund dieser Ergebnisse kann davon ausgegangen werden, dass die Zweitkodierung aller Schülerinnen und Schüler keine deutlich abweichende Resultate geliefert hätten und daher die Zweitkodierung von 15\% der Schülerinnen und Schüler ausreichend war um die Qualität und Reliabilität der Kodierung festzustellen.

Daher kann davon ausgegangen werden, dass die Reliabilität der Kodierung gegeben ist und die Kodierung korrekt und nachvollziehbar ist.

\subsection{Qualitätsstandards}

Ein Problem bei der Definition der Qualitätsstandards ist die Unterschiedliche Definition in der Literatur. So verwendete \citet{Gut2013a} noch eine andere Reihenfolge der Qualitätsstandards. Die in dieser Arbeit verwendete Reihenfolge der Qualitätsstandards basiert auf den Arbeiten von \citet{Metzger2013, Hild2014a}. Ein Problem dabei ist jedoch, dass die Schwellenwerte für das Erreichen der Qualitätsstandards nicht publiziert sind. Die Schwellenwerte wurde daher von internen Dokumenten von Pitt Hild übernommen.

Die erreichten Qualitätsstandards in Tabelle \ref{tab:QS} zeigen, dass insbesondere die Qualitäts-standards 3, 4 und 5 nur von einem geringen Prozentsatz der Schülerinnen und Schüler erreicht werden. Und es auch einen Unterschied in den erreichten Qualitätsstandards zwischen den einzelnen Test gibt. In dieser Arbeit wird nicht auf diese Unterschiede eingegangen. Dafür sei auf folgende Arbeit hingewiesen \citet{Sichau2015}. Diesen Unterschied in den erreichten Qualitätsstandards deckt sich jedoch mit den Ergebnissen von \citet{Metzger2013}.

\subsection{Niveaus}

Dieses schlechte Abschneiden der Klassen spiegelt sich auch in den erreichten Niveaus wieder. So sieht man in Tabelle \ref{tab:Niveau}, dass ein Grossteil der Schülerinnen und Schüler nicht über das Niveau 2 hinauskommen, sowohl beim unbedingten als auch beim bedingten Niveau. Im Vergleich zu \citet{Metzger2013} scheiden die Schülerinnen und Schüler in der 7. Klasse schlechter ab. 

Da leider der Zeitpunkt der Datenerhebung in der Arbeit von \citet{Metzger2013} nicht aufgeführt ist, ist nicht klar ob der frühe Zeitpunkt des Testes (beginn des ersten Halbjahres) einen eventuellen Einfluss auf das Abschneiden der Schülerinnen und Schüler hatte. So war dies bei allen Klassen bei denen diese Tests durchgeführt wurden, das erste Mal, dass sie in der Oberstufe experimentiert haben. Auch kannten die Schülerinnen und Schüler den Kraftmesser nicht und konnten nur durch ausprobieren herausfinden, wie dieser funktioniert. Daher ist die Vermutung, dass wenn der Test im zweiten Halbjahr der 7. Klasse durchgeführt wurde ein deutlich besseres Resultat erzielt werden könnte.



\section{Fragebogen}

Die verwendeten Fragen im Fragebogen aus SESSKO \citep{Schone2002} und die abgewandelten Fragen nach \citet{Dierks2014} wurden aus innere Konsistenz überprüft. Beide Skalen erreichten wie in \ref{txt:Cronbach} beschrieben eine sehr gute innere Konsistenz, insbesondere da Cronbach's $\alpha$ eher zu einer Unterschätzung der inneren Konsistenz führt \citep{Eisinga2013}. Auch durch das Weglassen einzelner Fragen würde die innere Konsistenz nicht verbessert werden (siehe Tabelle \ref{tab:SESSKO} und Tabelle \ref{tab:NatSK}). Daher kann angenommen werden, dass beide Skalen das jeweilige Selbstkonzept konsistent widerspiegeln und ausreichend Fragen zu jeder Skala vorhanden sind. 

Der Mittelwert aller Schülerinnen und Schüler beim "`Schulisches Selbstkonzept - absolut"' kann mit den Werten aus der Literatur \citep{Schone2002} verglichen werden. Dabei hat die hier untersuchte Schülergruppe ein leicht überdurchschnittliches Selbstkonzept verglichen mit der Referenzgruppe (4. - 10. Klasse in verschiedenen Deutsch Schulformen und Bundesländern.). Der Grund dafür könnte der erst kürzlich erfolgte Übertritt auf die Oberstufe und dort die Einteilung in die Sek A sein. 

\section{Unterschied zwischen den Klassen}

Vor der weiteren Analyse der Daten muss erst festgestellt werden, ob die Datensätze der einzelnen Klassen kombiniert werden dürfen. Wichtig ist dabei, dass der exakte Test nach Fischer verwendet wird und nicht der Chi-Quadrat-Test, da bei kleinen Datensätzen (wie dem hier Vorliegenden) der Chi-Quadrat-Test nicht geeignet ist \citep{Mehta1984}.

Für den exakten Fischer-Test wurden die erreichten Qualitätsstandards in den einzelnen Klassen verglichen. Die Qualitätsstandards wurden verwendet, da im Vergleich zu den Items das statistische Rauschen geringer ist und gleichzeitig nicht viel an Information verloren geht. Aus der Tabelle \ref{tab:KlassenVergleiche}, kann geschlossen werden, dass kein signifikanter Unterschied zwischen den einzelnen Klassen existiert, da alle p-Werte über 0.05 liegen.

Es dürfen daher alle Datensätze kombiniert werden, da das Erreichen eines Qualitäts-standards nicht davon abhängt in welcher Klasse ein Schüler oder eine Schülerin ist. Für alle weiteren Analysen wurden daher alle Datensätze kombiniert und nicht nach Klassen unterschieden.

\section{Ist das Abschneiden in den Tests unterschiedlich}

Nachdem gezeigt wurde, dass der ganze Datensatz insgesamt analysiert werden kann, wurde versucht die Forschungsfrage zu beantworten. Dafür ist es notwendig festzustellen, ob das Erreichen der Qualitätsstufen zwischen den unterschiedlichen Tests signifikant unterschiedlich ist.

Hierbei gibt es unterschiedliche Ergebnisse, wie in Tabelle \ref{tab:CorNiveau} ersichtlich ist. So ist die Korrelation zwischen den unbedingten Niveaus sind zwischen allen Tests signifikant. Das Spearmans $\rho$ liegt jeweils im leicht positiven Bereich, was auf eine leicht positive Korrelation hinweist. Bei dem bedingten Niveau ist nur der Test zwischen Test 201 und 305 signifikant.

Ein Grund für diese unterschiedlichen Resultate liegt vermutlich darin, das beim bedingten Niveau nur sehr wenig hohe Werte erreicht werden (siehe Tabelle \ref{tab:Niveau}). Daher kommt es zu einer geringen Datenlage bei Niveaus über 2, dies kann man auch sehr gut in den Darstellungen \ref{fig:corLev} sehen. Dies führt zu Problemen bei der Berechnung des Korrelationstestes für bedingte Niveaus, da nur sehr wenige Datenpunkte im Bereich über 2 verfügbar sind, an denen eine Verankerung stattfinden könnte. Bei besseren Schülerinnen und Schülern bei denen öfter ein höheres Niveau erreicht würde, wären diese Probleme nicht so fatal und man würde vermutlich bei beiden Niveaus eine Korrelation feststellen können.

Aufgrund der geringen Datenlage bei den bedingten Niveaus, wird der Fokus in der weiteren Arbeit auf die unbedingten Niveaus gesetzt. Aufgrund der Korrelationen zwischen diesen kann davon ausgegangen werden, dass das Erreichen eines unbedingten Niveaus in einem Test mit dem unbedingten Niveau in einem anderen Test signifikant leicht korreliert. Dies ist ein erster Hinweis darauf, dass das Erreichen eines Niveaus nicht abhängig ist in welchem Test dies erreicht wurde. Sondern rein von der Kompetenz des skalenbasierten Messens. 

\section{Rasch-Analyse}

Nach sind in der klassischen Testtheorie erste Hinweise auf die Beantwortung der Forschungsfrage gezeigt haben, wurde zusätzlich die probabilistische Testtheorie verwendet. Ein Grund diese Theorie zu verwenden ist, dass das Abgeben einer korrekten Antwort ein Zufallsprozess ist und nicht deterministisch. Aufgrund der zugrunde liegenden Daten wurde das dichotome Rasch Modell verwendet. Für das Modell wurden nur die unbedingten Qualitätsstandards verwendet, die bedingten Qualitätsstandards würden die Annahme des Rasch Modells, dass alle Items unabhängig voneinander sind, verletzt.

\subsection{Parameter-Schätzung}

Ein grosses Problem bei der Rasch-Analyse ist die Parameter-Schätzung. Das grösste Problem dabei ist, dass es im Moment in der Literatur nur zwei gängige Parameterschätzer gibt, welche im Detail analysiert wurden \citep{Fischer1995,Rost2004, Strobl2012}. Wie bereits geschrieben machen diese beiden Parameterschätzer Annahmen über die Zugrunde liegenden Daten. Bei den vorliegenden Daten kann insbesondere die Annahme über eine bestimmte Verteilung (der Einfachheit halber wird meistens eine Normalverteilung angenommen \citep{Rost2004}) der Personenfähigkeiten aufgrund der Zugrundliegeenden Daten nicht angenommen werden.

Mit beiden Parameterschätzern können zwar die Aufgaben Schwierigkeiten $\beta$ übereinstimmen geschätzt werden (siehe Darstellung \ref{fig:RaschVergleich}). Nach \citet{Rost2004} ist diese Schätzung jedoch deutlich unkritischer, wie die der Personen-Parameter. Bei den Personen-Parametern $\theta$ gibt es jedoch Unterschiede zwischen beiden Schätzen. Bei der bedingen Maximum-Likelihood-Schätzung können alle Personen-Parameter ohne Extrapolation berechnet werden. Dies ist bei der marginal Maximum-Likelihood-Schätzung nicht der Fall. Der Grund dafür liegt in der Annahme einer Normalverteilung der Personen-Parameter die der marginal Maximum-Likelihood-Schätzung zugrunde liegt. Bei grösseren Datensätzen mag diese Annahme gerechtfertigt sein, bei dem hier vorliegenden Datensatz ist dieser Schätzer jedoch nicht geeignet. Es wäre zwar prinzipiell möglich eine andere Verteilung als die Normalverteilung für die Personen-Parameter zu verwenden. Dafür müsste aber eine eigene Implementierung des Rasch-Modells vorgenommen werden, was den Rahmen dieser Arbeit sprengen würde.

Aufgrund diesem Vergleich der Parameter-Schätzungen wurde für alle weiteren Rasch Modelle der bedingen Maximum-Likelihood-Schätzer verwendet. Dessen Annahmen, dass jeder Schüler oder Schülerin mindestens ein Item richtig oder falsch beantwortet haben müssen, war jedoch bei der Aufteilung in kleinere Rasch-Modelle ein Problem. Daher sollten insbesondere für kleine Datensätze bessere Schätzer entwickelt werden, welche weniger Annahmen über die Zugrundliegeenden Daten machen. Eine Möglichkeit wäre ein Bootstrapping Algorithmus, welcher die Verteilung der Personen-Parameter aus den vorliegenden Daten selbst abschätzt und die Verteilung dann in den marginal Maximum-Likelihood Schätzer einsetzt.

\subsection{Modellkontrolle}

Nachdem der beste Parameter-Schätzer identifiziert wurde, musste das Rasch Modell jedoch noch verifiziert werden. Dafür wurde das Rasch-Modell basierend auf dem Mittelwert der Personen-Randsummen gesplittet. Aufgrund der Annahmen für das Rasch-Modell sollten dann keine signifikanten Unterschiede zwischen den beiden neuen Modellen existieren. Dies wurde vom Andersens Likelihood-Quotienten Test bestätigt, nach dem die Qualitätsstufen 4 und 5 entfernt wurden. Das Problem mit diesen beiden Qualitätsstufen ist, dass für die untersuchte Personen-Gruppe diese Standards sehr schwierig waren und sie daher kaum beantwortet wurden (siehe Tabelle \ref{tab:QS}). Aufgrund der Test Ergebnisse kann das Ausschliessen dieser Qualitätsstufen bestätigt werden, da dann ein valides Rasch-Modell vorliegt.

Zusätzlich wurden alle Qualitätsstandards noch überprüft, sowohl grafisch (siehe Darstellung \ref{fig:RaschKontrolle}), als auch mit dem Wald-Test (siehe Tabelle \ref{tab:WaldTest}). Es gab dabei kein Qualitätsstandard, welcher als ungeeignet aus dem Modell ausgeschlossen werden müsste, da er sich signifikant in den beiden Modellen unterschiedet.

Diese Resultate zeigen, dass das verwendete Rasch-Modell mit den Qualitätsstandards 1-3 valide ist. Dieses Resultat ist wichtig, da ansonsten die mit diesem Modell gewonnenen Parameter auf einer falschen Modell-Annahme beruhen würden.

\subsection{Unterschied in den Schwierigkeiten der Qualitätsstandards}

Die Schwierigkeit eines Qualitätsstandards sollte nicht davon abhängig sein, in welchem Test dieser Qualitätsstandard erreicht wurde. Dies wurde versucht mit Hilfe des Rasch-Modells zu verifizieren. Dazu wurden die \textit{item characteristic curves} (ICC) gezeichnet, siehe Darstellung \ref{fig:corLevRasch}. Diese Darstellung lassen eine qualitative Überprüfung der Schwierigkeiten dar. Man sieht das bei Qualitätsstandard 1 und 3 die beiden Test 201 und 301 sehr ähnlich sind. Bei Test 305 sind die Qualitätsstandards meistens deutlich leichter in der Schwierigkeit. Dies liegt höchstwahrscheinlich daran, dass dieser Test im Vergleich zu den anderen beiden Test leichter ist \citep{Sichau2015}. Dies sieht man auch in der Darstellung \ref{fig:PersonItemMapQ}.

Zusätzlich zu der qualitativen Überprüfung wurde noch ein Kolmogorow-Smirnow-Test durchgeführt, um festzustellen ob die Unterschiede in den Aufgaben-Parametern (siehe Tabelle \ref{tab:betaQ}) signifikant sind. Die Testergebnisse in Tabelle \ref{tab:corTestQ} zeigen, dass es keine signifikanten Unterschiede zwischen diesen Werten gibt. Wichtig ist dabei jedoch, dass diese Tests eine sehr geringe Power haben, da der Datensatz nur die Grösse von 3 hatte. Diese geringe Power zeigt sich auch in der Darstellung \ref{fig:corTestQ}.


Durch die Kombination der qualitativen und quantitativen Resultaten kann jedoch die Aussage gestützt werden, dass es keine signifikanten Unterschiede in der Schwierigkeiten der Qualitätsstandards gibt. Dies ist ein weiterer Hinweis darauf, dass das Erreichen der Qualitätsstandards 1-3 nicht davon abhängig ist, welcher Test durchgeführt wurde. 

\subsection{Unterschied in den latenten Personen-Fähigkeiten}

Nachdem es klar ist, dass die Aufgaben-Parameter sehr ähnlich sind wurden die Personen-Parameter analysiert. Hierfür wurde das Rasch-Modell aufteilt und für jeden Test ein eigenes Rasch-Modell erstellt. Hierbei gibt es nun massive Probleme mit der Parameter-Schätzung, da nun die Wahrscheinlichkeit, dass ein Schüler keinen der drei Qualitätsstandards oder alle erreicht hat, signifikant höher ist. Daher konnten viele Personen-Parameter nicht geschätzt werden.

Diese Probleme mit der Parameter-Schätzung führten auch dazu, dass das Modell nicht validiert werden konnten. Die gewonnenen Personen-Parameter basieren daher auf einem nicht validierten Modell und müssten daher mit Vorsicht interpretiert werden. Diesmal wurde daher untersucht, ob sich die Personen-Fähigkeiten zwischen den drei Rasch Modellen unterscheiden. In Tabelle \ref{tab:GOFP} und Darstellung \ref{fig:GOFP} sind die Resultate dieses Testes dargestellt. Es kann daher davon ausgegangen werden, dass die Personen-Fähigkeiten zwischen den drei Tests nicht signifikant korrelieren.

Diese Resultate sind ein Gegenindiz zu den bisher vorliegenden Resultaten, da die Personen-Fähigkeit nicht von den durchgeführten Tests abhängen sollten. Aufgrund der Datengrundlage und dem darauf basierenden Rasch-Modell sollten diese Ergebnisse jedoch nicht überbewertet werden, insbesondere da das Rasch-Modell nicht validiert werden konnte. Auch sieht man in Tabelle \ref{tab:GOFP}, dass meistens nur ein kleiner Teil der Personen-Parameter verglichen worden wurde, da der Schätzer nur für einen kleinen Teil der Personen fähig war den Personen-Parameter $\theta$ zu berechnen. Diese Ergebnisse beruhen daher Grossteils auf Problemen mit dem Parameter-Schätzer. Auch der marginale Maximum-Likelihood Schätzer hatte massive Probleme mit dem Datensatz und war noch schlechter, daher wurden dessen Ergebnisse nicht präsentiert.

Aufgrund dieser Probleme sollten diese Gegenindizien nicht überinterpretiert werden, da sie auf einer sehr schlechten Datengrundlage basieren. Dies zeigt jedoch, dass bessere Parameter-Schätzer notwendig sind, welche auch mit solchen Datensätzen umgehen können.

\subsection{Zusammenhang Rasch Modell und Fragebogen}

Das erste Rasch-Modell, bei dem alle drei Test kombiniert wurden, wurde verwendet um die latente Personen-Fähigkeit mit Resultaten des Fragebogens zu vergleichen. In Tabelle \ref{tab:CorPersonRasch} sind die Ergebnisse der Korrelations-Test dargestellt. Es gibt nur einen signifikanten Zusammenhand zwischen dem Schulversuch Selbstkonzept. 

Dieses Ergebnis ist nicht überraschend, da in der Notengebung experimentellen hand-ons Test eher eine untergeordnete Rolle spielen. Auch das SESSKO Selbstkonzept \citep{Schone2002} ist vermutlich zu generell und korreliert daher nicht mit den Personen-Fähigkeiten des Rasch-Modells. Das letzte Selbstkonzept hingegen zielt sehr genau auf das Selbstkonzept bei Schulversuchen ab, welche sehr identisch zu experimentellen hand-ons Test sind. Daher ist diese Korrelation zu erwarten. Um diese Skala jedoch zu verbessern, müsste diese noch im grösseren Rahmen validiert werden. Vor allem ist im Moment noch keine Normalverteilung der Daten gewährleistet.

\section{Videoanalyse}

In einem letzten Schritt wurden noch die Videos analysiert. Die dabei entwickelten Merkmale wurden mit den Qualitätsstandards korreliert. Wie in Tabelle \ref{tab:CorVideoQ} und Darstellung \ref{fig:corVideoQ} ersichtlich gibt es keinen Zusammenhang zwischen den im Video kodierten Merkmalen und den Qualitätsstandards, auf denen die Merkmale beruhen. Diese Ergebnisse sind zuerst enttäuschend, da die Merkmale eigentlich die Qualitätsstandards widerspiegeln sollten. Mit Beobachtungen, welche jedoch während der Test Durchführung gemacht wurden lassen sich diese Ergebnisse jedoch erklären. Viele Schülerinnen und Schüler waren während der Test Durchführung sehr auf die experimentelle Seite fokussiert und haben insgesamt sehr wenig auf den Datenbögen ausgefüllt. Dies zeigt sich auch im insgesamt eher schlechtem Abschneiden der Schülerinnen und Schüler (siehe Tabelle \ref{tab:Niveau}). Daher widerspiegeln die Qualitätsstandards nur den Teil des Experimentes wieder, welche die Schülerinnen und Schüler dokumentiert haben. 

Diese Resultate zeigen jedoch klar, dass die Kompetenz des skalenbaiserenden Messens auch der Aspekt der Dokumentation eine entscheidende Rolle spielt. Dies widerspricht sich jedoch nicht, da zu einer experimentellen Kompetenz die Fähigkeit zu Dokumentieren sehr wichtig ist. Für Schülerinnen und Schüler jedoch, welche sprachliche Schwächen haben, könnte der Einsatz von Videoanalysen hilfreich sein. Auch bei niedrigeren Schulstufen, wäre der Einsatz von Videoanalysen angebracht. Ein Nachteil ist jedoch der hohe Aufwand, welcher für die Kodierung der Videos anfällt. 

Ein weiteres Problem ist die Interpretierbarkeit der Daten. So ist es sehr schwierig aus der Darstellung \ref{fig:Messungen} gute Schlüsse zu ziehen. Diese Daten sind nur qualitativ analysierbar. Solange aber dieser Datensatz nicht grösser ist, sollten aus diesen Daten auch keine qualitativen Schlüsse gezogen werden.

\section{Zusammenfassung}

Abschliessend lässt sich sagen, dass sowohl mit der klassischen als auch mit der probabilistische Testtheorie die Forschungsfrage beantwortbar ist. Mit beiden Theorien konnten starke Hinweise darauf gefunden werden, dass bei dem vorliegenden Datensatz die Kompetenz des skalenbasierenden Messens unabhängig des fachlichen oder inhaltlichen Kontextes ist. Es gibt zwar auch Gegenanzeigen gegen dieses Resultat, bei diesen ist aber oft die Datengrundlage sehr schlecht, im Vergleich zu den unterstützenden Hinweisen. Daher kann die Forschungsfrage mit der durchgeführten Methode beantwortet werden. Bevor aber generelle Schlüsse gezogen werden sollten, müsste die Untersuchungsgruppe massiv vergrössert werden. 

Das Resultat dieser Arbeit ist daher, dass:
\begin{quote}
 Die Kompetenz des skalenbasierten Messens ist, in der vorliegenden Untersuchungsgruppe, unabhängig des fachlichen oder inhaltlichen Kontextes.
\end{quote}


